{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba400476-4adb-4e22-a515-35a7058ac663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OUTPUTS WRITTEN ===\n",
      "DP02 -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\DP02_travis_county.xlsx\n",
      "DP03 -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\DP03_travis_county.xlsx\n",
      "DP04 -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\DP04_travis_county.xlsx\n",
      "DP05 -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\DP05_travis_county.xlsx\n",
      "Combined ACS -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\combined_acs_travis_county.csv\n",
      "Dictionary   -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\data_dictionary.xlsx\n",
      "Crime+ACS    -> C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\\crime_with_acs_merge.csv\n",
      "\n",
      "=== QUICK CHECKS ===\n",
      "DP02: headers True, colsets True, desc True, travis True, georegex True\n",
      "DP03: headers True, colsets True, desc True, travis True, georegex True\n",
      "DP04: headers True, colsets True, desc True, travis True, georegex True\n",
      "DP05: headers True, colsets True, desc True, travis True, georegex True\n"
     ]
    }
   ],
   "source": [
    "# === DAT490: Final rebuild for DP02–DP05 + combined + crime merge (openpyxl header-safe) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from openpyxl import Workbook\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\nicol\\OneDrive\\DAT490\\Travis_County_ACS_2025-10-26T122106\")\n",
    "\n",
    "DP_FILES = {\n",
    "    \"DP02\": BASE / \"ACSDP5Y2023.DP02-Data.csv\",\n",
    "    \"DP03\": BASE / \"ACSDP5Y2023.DP03-Data.csv\",\n",
    "    \"DP04\": BASE / \"ACSDP5Y2023.DP04-Data.csv\",\n",
    "    \"DP05\": BASE / \"ACSDP5Y2023.DP05-Data.csv\",\n",
    "}\n",
    "CRIME_FILE = BASE / \"Crime_Reports.csv\"\n",
    "\n",
    "XLSX_OUT = {\n",
    "    \"DP02\": BASE / \"DP02_travis_county.xlsx\",\n",
    "    \"DP03\": BASE / \"DP03_travis_county.xlsx\",\n",
    "    \"DP04\": BASE / \"DP04_travis_county.xlsx\",\n",
    "    \"DP05\": BASE / \"DP05_travis_county.xlsx\",\n",
    "}\n",
    "COMBINED_OUT = BASE / \"combined_acs_travis_county.csv\"\n",
    "DICT_XLSX   = BASE / \"data_dictionary.xlsx\"\n",
    "MERGED_OUT  = BASE / \"crime_with_acs_merge.csv\"\n",
    "\n",
    "TRAVIS_GEO_REGEX = re.compile(r\"^1400000US48453\\d{6}$\")\n",
    "VAR_RE = re.compile(r\"^dp\\d{2}_\\d{4}(pe|pm|e|m)$\", re.IGNORECASE)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def clean_dp(df: pd.DataFrame, table_id: str):\n",
    "    \"\"\"Rename to geo_id, name, and lowercase ACS codes. Return (df, row2_descriptions).\"\"\"\n",
    "    df = df.copy()\n",
    "    row1, row2 = [], []\n",
    "    for c in df.columns:\n",
    "        if c == \"GEO_ID\":\n",
    "            row1.append(\"geo_id\")\n",
    "            row2.append(\"Census tract GEO_ID key (1400000US + state+county+tract)\")\n",
    "        elif c == \"NAME\":\n",
    "            row1.append(\"name\")\n",
    "            row2.append(\"Geographic area name\")\n",
    "        else:\n",
    "            lc = c.lower()\n",
    "            row1.append(lc)\n",
    "            if lc.endswith(\"pe\"):\n",
    "                row2.append(f\"{table_id} {c} percentage estimate\")\n",
    "            elif lc.endswith(\"pm\"):\n",
    "                row2.append(f\"{table_id} {c} percentage margin of error\")\n",
    "            elif lc.endswith(\"e\"):\n",
    "                row2.append(f\"{table_id} {c} estimate\")\n",
    "            elif lc.endswith(\"m\"):\n",
    "                row2.append(f\"{table_id} {c} margin of error\")\n",
    "            else:\n",
    "                row2.append(f\"{table_id} {c}\")\n",
    "    df.columns = row1\n",
    "    return df, row2\n",
    "\n",
    "def enforce_travis(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Keep only valid Travis County tract rows by GEO_ID pattern.\"\"\"\n",
    "    if \"geo_id\" not in df.columns:\n",
    "        return df\n",
    "    return df[df[\"geo_id\"].fillna(\"\").astype(str).str.match(TRAVIS_GEO_REGEX)]\n",
    "\n",
    "def write_xlsx_two_header_openpyxl(path: Path, row1: list, row2: list, df: pd.DataFrame):\n",
    "    \"\"\"Write exact two header rows + data using openpyxl to avoid pandas header alignment issues.\"\"\"\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"data\"\n",
    "    # Row 1: exact column names (must match df.columns)\n",
    "    ws.append(list(row1))\n",
    "    # Row 2: descriptions\n",
    "    ws.append(list(row2))\n",
    "    # Rows 3+: data rows (values only, in the same order as columns)\n",
    "    for tup in df.itertuples(index=False, name=None):\n",
    "        ws.append(list(tup))\n",
    "    wb.save(path)\n",
    "\n",
    "def derive_geo_id_from_cbg(series: pd.Series) -> pd.Series:\n",
    "    cbg = series.astype(str).str.replace(r\"\\D\", \"\", regex=True).str.zfill(10)\n",
    "    tract11 = \"48\" + cbg.str[:3] + cbg.str[3:9]\n",
    "    return \"1400000US\" + tract11\n",
    "\n",
    "# ---------- load & clean from RAW (fresh) ----------\n",
    "dp = {}\n",
    "row2_map = {}\n",
    "\n",
    "for dp_id, path in DP_FILES.items():\n",
    "    raw = pd.read_csv(path, dtype=str, low_memory=False)\n",
    "    df, r2 = clean_dp(raw, dp_id)\n",
    "    df = enforce_travis(df)\n",
    "    dp[dp_id] = df\n",
    "    row2_map[dp_id] = r2\n",
    "\n",
    "# ---------- write per-table Excel (openpyxl, exact headers) ----------\n",
    "for dp_id in [\"DP02\",\"DP03\",\"DP04\",\"DP05\"]:\n",
    "    cols = list(dp[dp_id].columns)\n",
    "    desc = row2_map[dp_id]\n",
    "    # sanity: ensure same length\n",
    "    assert len(cols) == len(desc), f\"Row2 length mismatch in {dp_id}\"\n",
    "    write_xlsx_two_header_openpyxl(XLSX_OUT[dp_id], cols, desc, dp[dp_id])\n",
    "\n",
    "# ---------- combine & save ----------\n",
    "combined = (\n",
    "    dp[\"DP02\"]\n",
    "    .merge(dp[\"DP03\"], on=[\"geo_id\",\"name\"], how=\"outer\")\n",
    "    .merge(dp[\"DP04\"], on=[\"geo_id\",\"name\"], how=\"outer\")\n",
    "    .merge(dp[\"DP05\"], on=[\"geo_id\",\"name\"], how=\"outer\")\n",
    ")\n",
    "combined.to_csv(COMBINED_OUT, index=False)\n",
    "\n",
    "# ---------- data dictionary ----------\n",
    "rows = []\n",
    "for dp_id in [\"DP02\",\"DP03\",\"DP04\",\"DP05\"]:\n",
    "    row1 = list(dp[dp_id].columns)\n",
    "    row2 = row2_map[dp_id]\n",
    "    for col, dsc in zip(row1, row2):\n",
    "        orig = col.upper() if VAR_RE.match(col) else col\n",
    "        rows.append([dp_id, col, dsc, orig])\n",
    "data_dict = pd.DataFrame(rows, columns=[\"source_table\",\"column_name\",\"short_description\",\"original_code\"])\n",
    "\n",
    "# write dictionary via pandas (no special headers needed here)\n",
    "try:\n",
    "    with pd.ExcelWriter(DICT_XLSX, engine=\"xlsxwriter\") as xw:\n",
    "        data_dict.to_excel(xw, index=False, sheet_name=\"Data_Dictionary\")\n",
    "        pd.DataFrame({\"Join & Cleaning Steps\": [\n",
    "            \"1) Loaded DP02–DP05 (ACS 2023 5-Year, Travis County).\",\n",
    "            \"2) Standardized headers: geo_id, name, and lowercase ACS codes; preserved original codes in dictionary.\",\n",
    "            \"3) Built deterministic Row 2: E/M/PE/PM labeled (estimate / margin of error / percentage estimate / percentage margin of error).\",\n",
    "            \"4) Enforced Travis GEO_ID pattern (1400000US48453xxxxxx).\",\n",
    "            \"5) Wrote Excel via openpyxl (no implicit headers), then combined (outer join on geo_id, name).\",\n",
    "            \"6) Derived crime geo_id from CBG and left-joined to ACS; kept merged file separate for integrity.\"\n",
    "        ]}).to_excel(xw, index=False, sheet_name=\"Join_Steps\")\n",
    "        pd.DataFrame([[\"Crime Reports (Austin, TX)\", \"https://catalog.data.gov/dataset/crime-reports-bf2b7\"],\n",
    "                      [\"ACS 5-Year Data Profiles (DP02–DP05)\", \"https://data.census.gov/\"]],\n",
    "                     columns=[\"Name\",\"Link\"]).to_excel(xw, index=False, sheet_name=\"Resources\")\n",
    "except ModuleNotFoundError:\n",
    "    with pd.ExcelWriter(DICT_XLSX, engine=\"openpyxl\") as xw:\n",
    "        data_dict.to_excel(xw, index=False, sheet_name=\"Data_Dictionary\")\n",
    "        pd.DataFrame({\"Join & Cleaning Steps\": [\n",
    "            \"1) Loaded DP02–DP05 (ACS 2023 5-Year, Travis County).\",\n",
    "            \"2) Standardized headers: geo_id, name, and lowercase ACS codes; preserved original codes in dictionary.\",\n",
    "            \"3) Built deterministic Row 2: E/M/PE/PM labeled (estimate / margin of error / percentage estimate / percentage margin of error).\",\n",
    "            \"4) Enforced Travis GEO_ID pattern (1400000US48453xxxxxx).\",\n",
    "            \"5) Wrote Excel via openpyxl (no implicit headers), then combined (outer join on geo_id, name).\",\n",
    "            \"6) Derived crime geo_id from CBG and left-joined to ACS; kept merged file separate for integrity.\"\n",
    "        ]}).to_excel(xw, index=False, sheet_name=\"Join_Steps\")\n",
    "        pd.DataFrame([[\"Crime Reports (Austin, TX)\", \"https://catalog.data.gov/dataset/crime-reports-bf2b7\"],\n",
    "                      [\"ACS 5-Year Data Profiles (DP02–DP05)\", \"https://data.census.gov/\"]],\n",
    "                     columns=[\"Name\",\"Link\"]).to_excel(xw, index=False, sheet_name=\"Resources\")\n",
    "\n",
    "# ---------- crime + ACS merge (chunked) ----------\n",
    "acs_full = pd.read_csv(COMBINED_OUT, dtype=str, low_memory=False)\n",
    "\n",
    "cbg_col = None\n",
    "for c in pd.read_csv(CRIME_FILE, nrows=0).columns:\n",
    "    if \"census\" in c.lower() and \"block\" in c.lower():\n",
    "        cbg_col = c; break\n",
    "\n",
    "first = True\n",
    "for chunk in pd.read_csv(CRIME_FILE, dtype=str, low_memory=False, chunksize=100_000):\n",
    "    if cbg_col:\n",
    "        chunk[\"geo_id\"] = derive_geo_id_from_cbg(chunk[cbg_col])\n",
    "    else:\n",
    "        chunk[\"geo_id\"] = np.nan\n",
    "    merged = chunk.merge(acs_full, on=\"geo_id\", how=\"left\")\n",
    "    merged.to_csv(MERGED_OUT, index=False, mode=\"w\" if first else \"a\", header=first)\n",
    "    first = False\n",
    "\n",
    "# ---------- mini checks ----------\n",
    "def read_two_header_xlsx_openpyxl(path: Path):\n",
    "    # for verification readback: use pandas header=None to capture both header rows\n",
    "    x = pd.read_excel(path, sheet_name=\"data\", header=None, dtype=str)\n",
    "    row1 = [str(v) for v in x.iloc[0].tolist()]\n",
    "    row2 = [(\"\" if pd.isna(v) else str(v)) for v in x.iloc[1].tolist()]\n",
    "    df   = x.iloc[2:].copy()\n",
    "    df.columns = row1\n",
    "    return row1, row2, df\n",
    "\n",
    "print(\"=== OUTPUTS WRITTEN ===\")\n",
    "for k,v in XLSX_OUT.items():\n",
    "    print(k, \"->\", v)\n",
    "print(\"Combined ACS ->\", COMBINED_OUT)\n",
    "print(\"Dictionary   ->\", DICT_XLSX)\n",
    "print(\"Crime+ACS    ->\", MERGED_OUT)\n",
    "\n",
    "print(\"\\n=== QUICK CHECKS ===\")\n",
    "for dp_id in [\"DP02\",\"DP03\",\"DP04\",\"DP05\"]:\n",
    "    r1, r2, df = read_two_header_xlsx_openpyxl(XLSX_OUT[dp_id])\n",
    "    ok1 = {\"geo_id\",\"name\"}.issubset(df.columns)\n",
    "    raw = pd.read_csv(DP_FILES[dp_id], dtype=str, low_memory=False)\n",
    "    raw_dp = [c for c in raw.columns if c not in (\"GEO_ID\",\"NAME\")]\n",
    "    df_dp  = [c for c in df.columns if c not in (\"geo_id\",\"name\")]\n",
    "    ok2 = set([c.lower() for c in raw_dp]) == set(df_dp)\n",
    "    def desc_ok(row1,row2):\n",
    "        VAR_RE2 = re.compile(r\"^dp\\d{2}_\\d{4}(pe|pm|e|m)$\")\n",
    "        for h,d in zip(row1,row2):\n",
    "            hl, dl = h.lower(), (d or \"\").lower()\n",
    "            if hl in (\"geo_id\",\"name\"):\n",
    "                if not ((\"geo\" in dl) or (\"geographic\" in dl)): return False\n",
    "                continue\n",
    "            if VAR_RE2.match(hl):\n",
    "                if hl.endswith((\"e\",\"pe\")) and \"estimate\" not in dl: return False\n",
    "                if hl.endswith((\"m\",\"pm\")) and \"margin of error\" not in dl: return False\n",
    "        return True\n",
    "    ok3 = desc_ok(r1, r2)\n",
    "    ok4 = df[\"name\"].fillna(\"\").str.contains(\"Travis County; Texas\", case=False).mean() > 0.95\n",
    "    ok5 = df[\"geo_id\"].fillna(\"\").astype(str).str.match(TRAVIS_GEO_REGEX).mean() > 0.95\n",
    "    print(f\"{dp_id}: headers {ok1}, colsets {ok2}, desc {ok3}, travis {ok4}, georegex {ok5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471b126-5626-4d24-b773-8353969e96ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
